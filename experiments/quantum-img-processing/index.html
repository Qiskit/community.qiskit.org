<!doctype html>
<html data-n-head-ssr>
  <head>
    <title>Quantum Image Processing</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="description" name="description" content="A quantum approach to image processing (encoding, edge detection & image matching) with a cool application => mapping the Earth at night."><meta data-n-head="ssr" data-hid="twitter:card" name="twitter:card" content="summary_large_image"><meta data-n-head="ssr" data-hid="twitter:site" name="twitter:site" content="@qiskit"><meta data-n-head="ssr" data-hid="twitter:title" name="twitter:title" content="Quantum Image Processing"><meta data-n-head="ssr" data-hid="twitter:description" name="twitter:description" content="A quantum approach to image processing (encoding, edge detection & image matching) with a cool application => mapping the Earth at night."><meta data-n-head="ssr" data-hid="twitter:image" name="twitter:image" content="undefined"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" href="/_nuxt/0e420db00daca0f8b5f6.js" as="script"><link rel="preload" href="/_nuxt/72991809f63374c339f2.js" as="script"><link rel="preload" href="/_nuxt/360d16368af7a3608f2c.js" as="script"><link rel="preload" href="/_nuxt/add2c23413c6b1a14c49.js" as="script"><link rel="preload" href="/_nuxt/21de77e847e508aa3811.js" as="script"><link rel="preload" href="/_nuxt/1e0c9336078fda31acbe.js" as="script"><link rel="preload" href="/_nuxt/6d9f2a32d4bdeb207aa2.js" as="script"><style data-vue-ssr-id="3191d5ad:0 46e2673a:0 513c256f:0 56284062:0 2b5f2c00:0 741c9dd6:0 930d47c8:0 0cd1eeaa:0 60183a00:0">.nuxt-progress{position:fixed;top:0;left:0;right:0;height:2px;width:0;opacity:1;transition:width .1s,opacity .4s;background-color:#fff;z-index:999999}.nuxt-progress.nuxt-progress-notransition{transition:none}.nuxt-progress-failed{background-color:red}@font-face{font-family:IBM Plex Mono;font-style:normal;font-weight:400;src:local("IBM Plex Mono"),local("IBMPlexMono"),url(/fonts/IBM-Plex-Mono/fonts/complete/woff/IBMPlexMono-Regular.woff) format("woff")}@font-face{font-family:IBM Plex Mono;font-style:italic;font-weight:400;src:local("IBM Plex Mono Italic"),local("IBMPlexMono-Italic"),url(/fonts/IBM-Plex-Mono/fonts/complete/woff/IBMPlexMono-Italic.woff) format("woff")}@font-face{font-family:IBM Plex Mono;font-style:normal;font-weight:700;src:local("IBM Plex Mono Bold"),local("IBMPlexMono-Bold"),url(/fonts/IBM-Plex-Mono/fonts/complete/woff/IBMPlexMono-Bold.woff) format("woff")}@font-face{font-family:IBM Plex Sans;font-style:italic;font-weight:700;src:local("IBM Plex Sans Bold Italic"),local("IBMPlexSans-BoldItalic"),url(/fonts/IBM-Plex-Sans/fonts/complete/woff/IBMPlexSans-BoldItalic.woff) format("woff")}@font-face{font-family:IBM Plex Sans;font-style:normal;font-weight:300;src:local("IBM Plex Sans Light"),local("IBMPlexSans-Light"),url(/fonts/IBM-Plex-Sans/fonts/complete/woff/IBMPlexSans-Light.woff) format("woff")}@font-face{font-family:IBM Plex Sans;font-style:italic;font-weight:300;src:local("IBM Plex Sans Light Italic"),local("IBMPlexSans-LightItalic"),url(/fonts/IBM-Plex-Sans/fonts/complete/woff/IBMPlexSans-LightItalic.woff) format("woff")}@font-face{font-family:IBM Plex Sans;font-style:normal;font-weight:400;src:local("IBM Plex Sans"),local("IBMPlexSans"),url(/fonts/IBM-Plex-Sans/fonts/complete/woff/IBMPlexSans-Regular.woff) format("woff")}html{font-family:IBM Plex Sans,Helvetica Neue,Arial,sans-serif;font-weight:300;font-size:18px}@media (min-width:830px){html{font-size:calc(18px + 2*(100vh - 830px)/ 270)}}@media (min-width:1000px){html{font-size:20px}}:root{--ibm-blue:#0a1d8f;--primary-color:#242a2e;--primary-color-dark:#161f25;--primary-color-darkmost:#0d1a22;--primary-color-light:#424c53;--primary-color-lightmost:#5d6870;--secondary-color:#893ffc;--secondary-color-light:#a167fc;--secondary-color-lightmost:#bc93fc;--secondary-color-dark:#6f16fa;--secondary-color-darkmost:#6105f2;--body-color-light:#e0e0e0;--body-color-dark:#333}h1{font-size:2.5rem}h2{font-size:2rem}p{margin-top:1.5rem}*{padding:0;margin:0;-webkit-overflow-scrolling:touch}#__layout,#__nuxt,body,html{height:100%;min-height:100%}.content-root *{box-sizing:border-box}.content-root{display:flex;flex-direction:column;height:100%;min-height:100%;overflow-x:hidden}.content-root>main{flex-grow:1}html{background-color:#242a2e;background-color:var(--primary-color)}[data-v-c28185c4]{box-sizing:border-box}.menu-container[data-v-c28185c4]{font-size:16px;font-weight:400;border-bottom:1px solid #000;background-color:#21252b;--link-color:#fff}.menu-container--light[data-v-c28185c4]{--link-color:var(--body-color-dark);background-color:var(--secondary-color-lightmost);border-bottom:none}.menu[data-v-c28185c4]{height:60px;display:flex;font-size:.8rem}.menu>[data-v-c28185c4]{height:100%}.menu--framed[data-v-c28185c4]{max-width:1100px;margin-left:auto;margin-right:auto;padding-left:2rem;padding-right:2rem}.navigation-group[data-v-c28185c4]{display:flex}.navigation-group__item[data-v-c28185c4]{display:inline-flex;align-items:center;padding:0 1em;color:var(--link-color);text-decoration:none}.navigation-group__item.nuxt-link-active[data-v-c28185c4]{font-weight:700;position:relative;top:1px;border-bottom:4px solid var(--secondary-color)}.navigation-group__item--active[data-v-c28185c4]{padding-top:2px;position:relative;top:1px;border-bottom:4px solid var(--secondary-color)}.navigation-group--with-separator[data-v-c28185c4]:before{content:"";background-color:hsla(0,0%,100%,.26667);width:2px;margin:12px 10px}.navigation-group--right-aligned[data-v-c28185c4]{margin-left:auto}.navigation-group--fixed[data-v-c28185c4]{margin-right:-.4rem}@media (max-width:54.99em){.navigation-group[data-v-c28185c4]{display:none}}.link-to-home[data-v-c28185c4]{display:inline-flex;align-items:center;margin-left:-1.2rem;padding:0 1em;color:var(--link-color);text-decoration:none}@media (max-width:54.99em){.link-to-home[data-v-c28185c4]{font-size:1.1rem;margin-left:-.5rem}}.drawer[data-v-c28185c4]{display:none}@media (max-width:54.99em){.drawer[data-v-c28185c4]{display:unset;margin-left:-2rem}}@media (max-width:54.99em){.community-menu[data-v-c28185c4]{display:none}}.drawer-toggle[data-v-c28185c4]{fill:#fff;height:100%;cursor:pointer;margin:0 0 0 1.5rem}.overlay[data-v-c28185c4]{right:0;z-index:150;background-color:#000;opacity:0;transition:opacity .2s;pointer-events:none}.overlay[data-v-c28185c4],.vertical-navigation[data-v-c28185c4]{position:fixed;top:0;bottom:0;left:0}.vertical-navigation[data-v-c28185c4]{display:flex;flex-direction:column;z-index:200;width:256px;padding:1.3rem;background-color:var(--primary-color);transform:translateX(-100%);transition:transform .2s;overflow-y:auto}.vertical-navigation h2[data-v-c28185c4]{font-size:.8rem;font-weight:400;color:var(--primary-color-lightmost);padding:1em}.vertical-navigation__item[data-v-c28185c4]{font-size:.9rem;text-decoration:none;color:#fff;padding:.5rem 1.5em}.vertical-community-navigation[data-v-c28185c4]{display:flex;flex-direction:column;margin:0 -1.3rem;padding:1rem 0;background-color:var(--secondary-color-lightmost)}.vertical-community-navigation__item[data-v-c28185c4]{font-size:.9rem;text-decoration:none;color:#fff;padding:.5rem 3rem;color:var(--body-color-dark)}.vertical-community-navigation__item.nuxt-link-active[data-v-c28185c4]{font-weight:700;border-left:4px solid var(--secondary-color);padding-left:calc(3rem - 4px)}.drawer:focus .vertical-navigation[data-v-c28185c4]{transform:translateX(0)}.drawer:focus .overlay[data-v-c28185c4]{opacity:.5}#copy[data-v-8dfd7e3c]{color:var(--body-color-dark);background-color:#fff;padding-top:0;padding-bottom:2rem}#copy[data-v-8dfd7e3c] .page-section{max-width:1100px;margin-left:auto;margin-right:auto;padding-left:2rem;padding-right:2rem}#copy[data-v-8dfd7e3c] ol,#copy[data-v-8dfd7e3c] ul{list-style-position:inside;padding-left:2rem;margin-top:1rem}#copy[data-v-8dfd7e3c] ul{list-style-type:square}#copy[data-v-8dfd7e3c] ol li,#copy[data-v-8dfd7e3c] ul li{margin:1rem 0}#copy[data-v-8dfd7e3c] h2{margin-top:3rem}#copy[data-v-8dfd7e3c] h3{margin-top:2rem}#copy[data-v-8dfd7e3c] p{text-align:justify}.experiment-header-container[data-v-2f83e77e]{background-color:#000;padding-top:1rem;padding-bottom:4rem}.experiment-header-container>div[data-v-2f83e77e]{max-width:1100px;margin-left:auto;margin-right:auto;padding-left:2rem;padding-right:2rem}.experiment-header-container h1[data-v-2f83e77e]{font-size:2.5rem;color:#fff}.experiment-header__author[data-v-2f83e77e]{color:var(--secondary-color-lightmost);margin:1rem 0}.experiment-header__author[data-v-2f83e77e]:before{content:"by";color:var(--primary-color-lightmost)}.experiment-header__back-navigation[data-v-2f83e77e]{height:100%;vertical-align:middle;display:inline-flex;text-decoration:none;color:var(--secondary-color-lightmost);margin-bottom:2rem}.experiment-header__back-navigation[data-v-2f83e77e]:hover{border-bottom:1px solid var(--secondary-color-lightmost)}.experiment-header__back-navigation svg[data-v-2f83e77e]{width:.5rem}.experiment-header__back-navigation svg path[data-v-2f83e77e]{fill:var(--secondary-color-lightmost)}.experiment-header__back-navigation svg[data-v-2f83e77e]:last-child{margin-right:.25rem}.experiment-header__cta[data-v-2f83e77e]{margin-right:1rem}.experiment-header__media[data-v-2f83e77e]{width:100%}@media (min-width:37.5em){.experiment-header__media>[data-v-2f83e77e]{max-width:100%}}@media (min-width:37.5em){.experiment-header__media[data-v-2f83e77e]>:first-child{grid-column-start:1;grid-column-end:3}}@media (min-width:37.5em){.experiment-header__media[data-v-2f83e77e]{display:grid;grid-template-columns:repeat(2,1fr);grid-gap:.5rem}}.button[data-v-4ce719e7]{padding:.66rem 1rem;background-color:var(--primary-color);border:2px solid var(--secondary-color);font-size:.75em;font-weight:100;color:#fff;text-transform:uppercase;text-decoration:none;box-shadow:0 4px 6px rgba(50,50,93,.11),0 1px 3px rgba(0,0,0,.08);white-space:nowrap;line-height:4rem}.button--secondary[data-v-4ce719e7]{color:#000;background-color:#fff}iframe[data-v-56c10029],img[data-v-56c10029],video[data-v-56c10029]{max-width:100%}.page-section-container[data-v-7a016f78]{padding-top:4rem;padding-bottom:4rem}.page-section[data-v-7a016f78]{display:flex;flex-direction:row}.page-section>[data-v-7a016f78]{width:50%}.page-section--reversed[data-v-7a016f78]{flex-direction:row-reverse}.copy-container[data-v-7a016f78]{width:50%}.copy-container--alone[data-v-7a016f78]{width:100%}@media (max-width:37.49em){.copy-container[data-v-7a016f78]{width:100%}}.extra-container[data-v-7a016f78]{width:50%}@media (max-width:37.49em){.importance--decoration[data-v-7a016f78]{display:none}}.page-footer-container[data-v-180070fc]{margin-top:4rem;padding-bottom:4rem}.page-footer[data-v-180070fc]{display:flex;flex-direction:row;font-size:.9rem;color:var(--primary-color-lightmost)}.page-footer ul[data-v-180070fc]{list-style:none;margin-top:1.5rem}.page-footer li[data-v-180070fc]{margin-top:.5rem;display:inline-block;width:100%}.page-footer--framed[data-v-180070fc]{max-width:1100px;margin-left:auto;margin-right:auto;padding-left:2rem;padding-right:2rem}@media (max-width:37.49em){.page-footer[data-v-180070fc]{display:block}}.footer-column[data-v-180070fc]{flex:1;margin-right:2rem}.footer-column__title[data-v-180070fc]{margin-top:2rem;font-size:inherit;font-weight:400;padding-bottom:.5rem;border-bottom:1px solid var(--primary-color-lightmost)}.footer-column__title[data-v-180070fc]:first-child{margin-top:0}@media (max-width:37.49em){.footer-column__title[data-v-180070fc]:first-child{margin-top:0}}.footer-column__link[data-v-180070fc]{color:inherit;text-decoration:none;display:inline-block;width:100%}.footer-column__link[data-v-180070fc]:hover{color:var(--body-color-light)}.footer-column[data-v-180070fc]:last-child{margin-right:0}@media (max-width:37.49em){.footer-column[data-v-180070fc]{margin-top:2rem;margin-right:0}}</style>
  </head>
  <body>
    <div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div tabindex="-1" class="content-root"><header id="navigation"><section data-v-c28185c4><div class="menu-container" data-v-c28185c4><div class="menu menu--framed" data-v-c28185c4><section tabindex="-1" class="drawer" data-v-c28185c4><svg height="24" viewBox="0 0 24 24" width="24" class="drawer-toggle" data-v-c28185c4><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z" data-v-c28185c4></path></svg> <div class="overlay" data-v-c28185c4></div> <nav class="vertical-navigation" data-v-c28185c4><h2 data-v-c28185c4>Elements</h2> <a href="https://qiskit.org/terra" class="vertical-navigation__item" data-v-c28185c4>
            Terra
          </a><a href="https://qiskit.org/aer" class="vertical-navigation__item" data-v-c28185c4>
            Aer
          </a><a href="https://qiskit.org/aqua" class="vertical-navigation__item" data-v-c28185c4>
            Aqua
          </a><a href="https://qiskit.org/ignis" class="vertical-navigation__item" data-v-c28185c4>
            Ignis
          </a><a href="https://qiskit.org/ibmqaccount" class="vertical-navigation__item" data-v-c28185c4>
            IBM Q Account
          </a> <h2 data-v-c28185c4>Learn more</h2> <a href="/" class="vertical-navigation__item vertical-navigation__item--active" data-v-c28185c4>Community</a> <div class="vertical-community-navigation" data-v-c28185c4><a href="/education" class="vertical-community-navigation__item" data-v-c28185c4>
              Education
            </a><a href="/advocates" class="vertical-community-navigation__item" data-v-c28185c4>
              Advocates
            </a><a href="/experiments" class="nuxt-link-active vertical-community-navigation__item nuxt-link-active" data-v-c28185c4>
              Experiments
            </a></div> <a href="https://quantum-computing.ibm.com/jupyter/tutorial/1_start_here.ipynb" target="_blank" class="vertical-navigation__item" data-v-c28185c4>Tutorials</a> <a href="https://qiskit.org/documentation" class="vertical-navigation__item" data-v-c28185c4>API Documentation</a></nav></section> <a href="https://qiskit.org" class="link-to-home" data-v-c28185c4>Qiskit</a> <nav class="navigation-group navigation-group--with-separator" data-v-c28185c4><a href="https://qiskit.org/terra" class="navigation-group__item" data-v-c28185c4>
          Terra
        </a><a href="https://qiskit.org/aer" class="navigation-group__item" data-v-c28185c4>
          Aer
        </a><a href="https://qiskit.org/aqua" class="navigation-group__item" data-v-c28185c4>
          Aqua
        </a><a href="https://qiskit.org/ignis" class="navigation-group__item" data-v-c28185c4>
          Ignis
        </a><a href="https://qiskit.org/ibmqaccount" class="navigation-group__item" data-v-c28185c4>
          IBM Q Account
        </a></nav> <nav class="navigation-group navigation-group--fixed navigation-group--right-aligned" data-v-c28185c4><a href="/" class="navigation-group__item navigation-group__item--active" data-v-c28185c4>Community</a> <a href="https://quantum-computing.ibm.com/jupyter/tutorial/1_start_here.ipynb" target="_blank" class="navigation-group__item" data-v-c28185c4>Tutorials</a> <a href="https://qiskit.org/documentation" class="navigation-group__item" data-v-c28185c4>API Documentation</a></nav></div></div> <div class="community-menu menu-container menu-container--light" data-v-c28185c4><section class="menu menu--framed" data-v-c28185c4><nav class="navigation-group navigation-group--right-aligned navigation-group--fixed" data-v-c28185c4><a href="/education" class="navigation-group__item" data-v-c28185c4>
          Education
        </a><a href="/advocates" class="navigation-group__item" data-v-c28185c4>
          Advocates
        </a><a href="/experiments" class="nuxt-link-active navigation-group__item nuxt-link-active" data-v-c28185c4>
          Experiments
        </a></nav></section></div></section></header> <main data-v-8dfd7e3c><header data-v-8dfd7e3c><div class="experiment-header-container" data-v-2f83e77e data-v-8dfd7e3c><div data-v-2f83e77e><a href="/experiments" class="experiment-header__back-navigation nuxt-link-active" data-v-2f83e77e><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11 18" data-v-2f83e77e><path fill="#999" d="M8.681.196l2.121 2.12-8.484 8.487-2.12-2.12z" data-v-2f83e77e></path> <path fill="#999" d="M10.803 15.047l-2.121 2.121L.197 8.683l2.121-2.121z" data-v-2f83e77e></path></svg> <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11 18" data-v-2f83e77e><path fill="#999" d="M8.681.196l2.121 2.12-8.484 8.487-2.12-2.12z" data-v-2f83e77e></path> <path fill="#999" d="M10.803 15.047l-2.121 2.121L.197 8.683l2.121-2.121z" data-v-2f83e77e></path></svg>
      Back to experiments
    </a> <h1 data-v-2f83e77e>Quantum Image Processing</h1> <p class="experiment-header__author" data-v-2f83e77e>
      Harold Co, Elena Peña Tapia, Nozomi Tanetani, Jean Philippe Arias Zapata, Lucía García Sánchez-Carnerero
    </p> <!----> <a href="https://github.com/Shedka/citiesatnight" rel="noopener" target="_blank" class="experiment-header__cta button button--secondary" data-v-4ce719e7 data-v-2f83e77e>
      Explore the code
    </a> <div class="experiment-header__media" data-v-2f83e77e><div class="media-container" data-v-56c10029 data-v-2f83e77e><img src="/images/experiments/quantum-img-processing/img-candidates.png" data-v-56c10029> <!----> <!----> <!----></div></div></div></div></header> <article id="copy" class="page-section-container" data-v-7a016f78 data-v-8dfd7e3c><div class="page-section" data-v-7a016f78><div class="copy-container copy-container--alone" data-v-7a016f78><div class="content" data-v-8dfd7e3c><p>A quantum approach to image processing: encoding, edge detection & image matching with a cool application: <em>mapping the Earth at night</em>.</p> <h2 id="application-background-and-motivation">Application Background and Motivation</h2> <p>Cities at Night (<a href="http://www.citiesatnight.org" target="_blank" rel="noopener">www.citiesatnight.org</a>) is an ongoing project by Alejandro Sanchez de Miguel (U. of Exeter) et al. focused on the creation of a high resolution map of the Earth at night, using color photographs taken by astronauts onboard the ISS.</p> <p>NASA has a database with almost 1 million cluttered, unlabeled pictures taken from space over the years. In order to create a high resolution world map, these photographs must be matched with their precise location in the globe's surface, a task for which the use of classical machine learning algorithms has been deemed ineffective. The current alternative has been to use citizen science and benefit from the manual matchings carried out by thousands of volunteers, but .... could this approach be improved?</p> <p>We think the answer is YES!, and for this hackathon we have decided to explore the benefits quantum computing can bring to this and many other computer vision based science intiatives, using current public available tools such as IBM Qiskit.</p> <h2 id="goals">Goals</h2> <p>The aim of the project is to develop a Python-based module to perform image matching using quantum computing tools (Qiskit). As an inital approach, the image matching process has been divided into the following tasks:</p> <ol><li>Classical image preparation</li> <li>Quantum encoding</li> <li>Quantum edge detection</li> <li>Quantum image matching</li></ol> <p>These tasks will be studied in order to fullfill the <strong>main goal of the project: a minimally viable product (MVP) where 3 classical images (1 reference and 2 proposals) are inputted, encoded, compared and matched</strong>; such as the proposal that best fits the reference is matched with it.</p> <h2 id="proposed-implementation">Proposed Implementation</h2> <ul><li><strong>Step 1: Image Preparation</strong>
This step involves preparing the inital images to adapt our problem to the scope of the hackathon by:
<ul><li>changing from RGB to grayscale format</li> <li>cropping the image to a square</li> <li>reducing the resolution to 32 x 32 pixels (this will later mean using 24 qubits in our computation, with the current limit of the qasm simulator being 32 quibts)</li> <li>centering the city within the image (using centroid)</li> <li>discarding particularly challenging pictures: those that are cropped, taken from a strange perspective....</li></ul></li></ul> <p>This is step involves Python classical image processing libraries such as PIL, OpenCV, etc. together with self developed functions.</p> <ul><li><strong>Step 2: Quantum Encoding</strong>
The quantum encoding or Quantum Image Representation (QImR) step involves the transformation of the data from a classical to a quantum image representation model [1]. The chosen quantum representation model is key to determine the types of processing tasks and how well they can be performed. After studying different proposals such as NEQR [2], in order to develop our MVP, we have selected to apply Flexible Representation of Quantum Images (FRQI) [3]. This allows us to encode an image of size <em>m = n x n</em> (pixels) into <em>log2(m)</em> qubits. One of the drawbacks of this representation is the requirement of <em>m</em> gates to perform the encoding of such an image.</li></ul> <p>Even though the main application has been developed using FRQI, we have looked for alterntives to optimize the number of gates required in our circuit. A suggested alternative is the use of a a "log concave based" encoding, of which we have attempted a proof of concept with a downscaled example.</p> <ul><li><strong>Step 3: Quantum Edge Detection</strong>
In classical image processing, one of the most common steps preceding image matching is edge detection. Several papers have claimed the computational advantage of quantum edge detection compared to the classical counterpart [1], and there have been proposed quantum models that provide a proof of concept such as [1] and [4].  Some other ideas based on the classical approach would be to use quantum support vector machines, inspired by [5].</li></ul> <p>For this project, we have implemented the work proposed in [1] that allows to detect horizontal and vertical edges, and find vertices by assesing their overlap in order to construct the image's contour.</p> <ul><li><strong>Step 4: Quantum Image Matching</strong>
Image matching involves finding similarities between images. These similiarties range from pixel to pixel differences to morphological properties. The qubits used to encode both the test and reference images represent the density matrices for each image. These density matrices can then be compared via a quantum based similarity test. Specifically, this involves a standard SWAP test [6].</li></ul> <h1 id="framework">Framework</h1> <ul><li>Language: Python3</li> <li>Quantum API: Qiskit</li> <li>Backend: ibmq_qasm_simulator</li></ul> <h1 id="references">References</h1> <ul><li>[1] <a href="https://arxiv.org/pdf/1801.01465.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1801.01465.pdf</a></li> <li>[2] <a href="https://arxiv.org/pdf/1812.11042.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1812.11042.pdf</a></li> <li>[3] <a href="https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf" target="_blank" rel="noopener">https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf</a></li> <li>[4] <a href="https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm" target="_blank" rel="noopener">https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm</a></li> <li>[5] <a href="https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf" target="_blank" rel="noopener">https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf</a></li> <li>[6] <a href="https://arxiv.org/abs/1803.04114" target="_blank" rel="noopener">https://arxiv.org/abs/1803.04114</a></li></ul></div></div> <!----></div></article></main> <footer data-v-180070fc><div class="page-footer-container" data-v-180070fc><div class="page-footer page-footer--framed" data-v-180070fc><section class="footer-column" data-v-180070fc><h2 class="footer-column__title" data-v-180070fc>
          Qiskit Elements
        </h2> <ul data-v-180070fc><li data-v-180070fc><a href="https://qiskit.org/terra" class="footer-column__link" data-v-180070fc>
              Terra
            </a></li><li data-v-180070fc><a href="https://qiskit.org/aer" class="footer-column__link" data-v-180070fc>
              Aer
            </a></li><li data-v-180070fc><a href="https://qiskit.org/aqua" class="footer-column__link" data-v-180070fc>
              Aqua
            </a></li><li data-v-180070fc><a href="https://qiskit.org/ignis" class="footer-column__link" data-v-180070fc>
              Ignis
            </a></li><li data-v-180070fc><a href="https://qiskit.org/ibmqaccount" class="footer-column__link" data-v-180070fc>
              IBM Q Account
            </a></li></ul></section> <section class="footer-column" data-v-180070fc><h2 class="footer-column__title" data-v-180070fc>
          Qiskit for Educators
        </h2> <ul data-v-180070fc><li data-v-180070fc><a href="/textbook" class="footer-column__link" data-v-180070fc>
              Textbook
            </a></li> <li data-v-180070fc><a href="https://www.youtube.com/playlist?list=PLOFEBzvs-Vvp2xg9-POLJhQwtVktlYGbY" target="_blank" rel="noopener" class="footer-column__link" data-v-180070fc>Coding With Qiskit</a></li> <li data-v-180070fc><a href="mailto:hello@qiskit.camp" target="_blank" rel="noopener" class="footer-column__link" data-v-180070fc>Host an Event</a></li></ul> <h2 class="footer-column__title" data-v-180070fc>
          Qiskit Advocates
        </h2> <ul data-v-180070fc><li data-v-180070fc><a href="/advocates#become-an-advocate" class="footer-column__link" data-v-180070fc>
              Become an Advocate
            </a></li></ul> <h2 class="footer-column__title" data-v-180070fc>
          Qiskit Experiments
        </h2> <ul data-v-180070fc><li data-v-180070fc><a href="/experiments#browse-the-experiments" class="footer-column__link" data-v-180070fc>
              Browse the experiments
            </a></li></ul></section> <section class="footer-column" data-v-180070fc><h2 class="footer-column__title" data-v-180070fc>
          Social Media
        </h2> <ul data-v-180070fc><li data-v-180070fc><a href="https://github.com/Qiskit" target="_blank" rel="noopener" class="footer-column__link" data-v-180070fc>
              GitHub
            </a></li><li data-v-180070fc><a href="https://qiskit.slack.com/" target="_blank" rel="noopener" class="footer-column__link" data-v-180070fc>
              Slack
            </a></li><li data-v-180070fc><a href="https://twitter.com/Qiskit" target="_blank" rel="noopener" class="footer-column__link" data-v-180070fc>
              Twitter
            </a></li><li data-v-180070fc><a href="https://medium.com/Qiskit" target="_blank" rel="noopener" class="footer-column__link" data-v-180070fc>
              Medium
            </a></li><li data-v-180070fc><a href="https://www.youtube.com/Qiskit" target="_blank" rel="noopener" class="footer-column__link" data-v-180070fc>
              YouTube
            </a></li><li data-v-180070fc><a href="https://quantumcomputing.stackexchange.com/questions/tagged/qiskit" target="_blank" rel="noopener" class="footer-column__link" data-v-180070fc>
              Stack Exchange
            </a></li></ul></section></div></div></footer></div></div></div><script>window.__NUXT__=function(e){return{layout:"second-level",data:[{title:"Quantum Image Processing",author:"Harold Co, Elena Peña Tapia, Nozomi Tanetani, Jean Philippe Arias Zapata, Lucía García Sánchez-Carnerero",description:"A quantum approach to image processing (encoding, edge detection & image matching) with a cool application => mapping the Earth at night.",image:e,to:"/experiments/quantum-img-processing",media:[e],source:"https://github.com/Shedka/citiesatnight",_meta:{resourcePath:"/home/travis/build/qiskit-community/community.qiskit.org/content/experiments/quantum-img-processing.md"},launch:void 0,render:"return function render() { var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0) }",staticRenderFns:'return [function () { var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c(\'div\',{staticClass:"content"},[_c(\'p\',[_vm._v("A quantum approach to image processing: encoding, edge detection & image matching with a cool application: "),_c(\'em\',[_vm._v("mapping the Earth at night")]),_vm._v(".")]),_vm._v(" "),_c(\'h2\',{attrs:{"id":"application-background-and-motivation"}},[_vm._v("Application Background and Motivation")]),_vm._v(" "),_c(\'p\',[_vm._v("Cities at Night ("),_c(\'a\',{attrs:{"href":"http://www.citiesatnight.org","target":"_blank","rel":"noopener"}},[_vm._v("www.citiesatnight.org")]),_vm._v(") is an ongoing project by Alejandro Sanchez de Miguel (U. of Exeter) et al. focused on the creation of a high resolution map of the Earth at night, using color photographs taken by astronauts onboard the ISS.")]),_vm._v(" "),_c(\'p\',[_vm._v("NASA has a database with almost 1 million cluttered, unlabeled pictures taken from space over the years. In order to create a high resolution world map, these photographs must be matched with their precise location in the globe\'s surface, a task for which the use of classical machine learning algorithms has been deemed ineffective. The current alternative has been to use citizen science and benefit from the manual matchings carried out by thousands of volunteers, but .... could this approach be improved?")]),_vm._v(" "),_c(\'p\',[_vm._v("We think the answer is YES!, and for this hackathon we have decided to explore the benefits quantum computing can bring to this and many other computer vision based science intiatives, using current public available tools such as IBM Qiskit.")]),_vm._v(" "),_c(\'h2\',{attrs:{"id":"goals"}},[_vm._v("Goals")]),_vm._v(" "),_c(\'p\',[_vm._v("The aim of the project is to develop a Python-based module to perform image matching using quantum computing tools (Qiskit). As an inital approach, the image matching process has been divided into the following tasks:")]),_vm._v(" "),_c(\'ol\',[_c(\'li\',[_vm._v("Classical image preparation")]),_vm._v(" "),_c(\'li\',[_vm._v("Quantum encoding")]),_vm._v(" "),_c(\'li\',[_vm._v("Quantum edge detection")]),_vm._v(" "),_c(\'li\',[_vm._v("Quantum image matching")])]),_vm._v(" "),_c(\'p\',[_vm._v("These tasks will be studied in order to fullfill the "),_c(\'strong\',[_vm._v("main goal of the project: a minimally viable product (MVP) where 3 classical images (1 reference and 2 proposals) are inputted, encoded, compared and matched")]),_vm._v("; such as the proposal that best fits the reference is matched with it.")]),_vm._v(" "),_c(\'h2\',{attrs:{"id":"proposed-implementation"}},[_vm._v("Proposed Implementation")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_c(\'strong\',[_vm._v("Step 1: Image Preparation")]),_vm._v("\\nThis step involves preparing the inital images to adapt our problem to the scope of the hackathon by:\\n"),_c(\'ul\',[_c(\'li\',[_vm._v("changing from RGB to grayscale format")]),_vm._v(" "),_c(\'li\',[_vm._v("cropping the image to a square")]),_vm._v(" "),_c(\'li\',[_vm._v("reducing the resolution to 32 x 32 pixels (this will later mean using 24 qubits in our computation, with the current limit of the qasm simulator being 32 quibts)")]),_vm._v(" "),_c(\'li\',[_vm._v("centering the city within the image (using centroid)")]),_vm._v(" "),_c(\'li\',[_vm._v("discarding particularly challenging pictures: those that are cropped, taken from a strange perspective....")])])])]),_vm._v(" "),_c(\'p\',[_vm._v("This is step involves Python classical image processing libraries such as PIL, OpenCV, etc. together with self developed functions.")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_c(\'strong\',[_vm._v("Step 2: Quantum Encoding")]),_vm._v("\\nThe quantum encoding or Quantum Image Representation (QImR) step involves the transformation of the data from a classical to a quantum image representation model [1]. The chosen quantum representation model is key to determine the types of processing tasks and how well they can be performed. After studying different proposals such as NEQR [2], in order to develop our MVP, we have selected to apply Flexible Representation of Quantum Images (FRQI) [3]. This allows us to encode an image of size "),_c(\'em\',[_vm._v("m = n x n")]),_vm._v(" (pixels) into "),_c(\'em\',[_vm._v("log2(m)")]),_vm._v(" qubits. One of the drawbacks of this representation is the requirement of "),_c(\'em\',[_vm._v("m")]),_vm._v(" gates to perform the encoding of such an image.")])]),_vm._v(" "),_c(\'p\',[_vm._v("Even though the main application has been developed using FRQI, we have looked for alterntives to optimize the number of gates required in our circuit. A suggested alternative is the use of a a \\"log concave based\\" encoding, of which we have attempted a proof of concept with a downscaled example.")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_c(\'strong\',[_vm._v("Step 3: Quantum Edge Detection")]),_vm._v("\\nIn classical image processing, one of the most common steps preceding image matching is edge detection. Several papers have claimed the computational advantage of quantum edge detection compared to the classical counterpart [1], and there have been proposed quantum models that provide a proof of concept such as [1] and [4].  Some other ideas based on the classical approach would be to use quantum support vector machines, inspired by [5].")])]),_vm._v(" "),_c(\'p\',[_vm._v("For this project, we have implemented the work proposed in [1] that allows to detect horizontal and vertical edges, and find vertices by assesing their overlap in order to construct the image\'s contour.")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_c(\'strong\',[_vm._v("Step 4: Quantum Image Matching")]),_vm._v("\\nImage matching involves finding similarities between images. These similiarties range from pixel to pixel differences to morphological properties. The qubits used to encode both the test and reference images represent the density matrices for each image. These density matrices can then be compared via a quantum based similarity test. Specifically, this involves a standard SWAP test [6].")])]),_vm._v(" "),_c(\'h1\',{attrs:{"id":"framework"}},[_vm._v("Framework")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_vm._v("Language: Python3")]),_vm._v(" "),_c(\'li\',[_vm._v("Quantum API: Qiskit")]),_vm._v(" "),_c(\'li\',[_vm._v("Backend: ibmq_qasm_simulator")])]),_vm._v(" "),_c(\'h1\',{attrs:{"id":"references"}},[_vm._v("References")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_vm._v("[1] "),_c(\'a\',{attrs:{"href":"https://arxiv.org/pdf/1801.01465.pdf","target":"_blank","rel":"noopener"}},[_vm._v("https://arxiv.org/pdf/1801.01465.pdf")])]),_vm._v(" "),_c(\'li\',[_vm._v("[2] "),_c(\'a\',{attrs:{"href":"https://arxiv.org/pdf/1812.11042.pdf","target":"_blank","rel":"noopener"}},[_vm._v("https://arxiv.org/pdf/1812.11042.pdf")])]),_vm._v(" "),_c(\'li\',[_vm._v("[3] "),_c(\'a\',{attrs:{"href":"https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf","target":"_blank","rel":"noopener"}},[_vm._v("https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf")])]),_vm._v(" "),_c(\'li\',[_vm._v("[4] "),_c(\'a\',{attrs:{"href":"https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm","target":"_blank","rel":"noopener"}},[_vm._v("https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm")])]),_vm._v(" "),_c(\'li\',[_vm._v("[5] "),_c(\'a\',{attrs:{"href":"https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf","target":"_blank","rel":"noopener"}},[_vm._v("https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf")])]),_vm._v(" "),_c(\'li\',[_vm._v("[6] "),_c(\'a\',{attrs:{"href":"https://arxiv.org/abs/1803.04114","target":"_blank","rel":"noopener"}},[_vm._v("https://arxiv.org/abs/1803.04114")])])])]) }]',component:{data:{},render:{},created:{}}}],error:null,serverRendered:!0}}("/images/experiments/quantum-img-processing/img-candidates.png")</script><script src="/_nuxt/0e420db00daca0f8b5f6.js" defer></script><script src="/_nuxt/add2c23413c6b1a14c49.js" defer></script><script src="/_nuxt/21de77e847e508aa3811.js" defer></script><script src="/_nuxt/1e0c9336078fda31acbe.js" defer></script><script src="/_nuxt/6d9f2a32d4bdeb207aa2.js" defer></script><script src="/_nuxt/72991809f63374c339f2.js" defer></script><script src="/_nuxt/360d16368af7a3608f2c.js" defer></script>
  </body>
</html>
