(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{165:function(e,t){e.exports={body:"A quantum approach to image processing: encoding, edge detection & image matching with a cool application: *mapping the Earth at night*.\n\n## Application Background and Motivation\nCities at Night (www.citiesatnight.org) is an ongoing project by Alejandro Sanchez de Miguel (U. of Exeter) et al. focused on the creation of a high resolution map of the Earth at night, using color photographs taken by astronauts onboard the ISS. \n\nNASA has a database with almost 1 million cluttered, unlabeled pictures taken from space over the years. In order to create a high resolution world map, these photographs must be matched with their precise location in the globe's surface, a task for which the use of classical machine learning algorithms has been deemed ineffective. The current alternative has been to use citizen science and benefit from the manual matchings carried out by thousands of volunteers, but .... could this approach be improved?\n\nWe think the answer is YES!, and for this hackathon we have decided to explore the benefits quantum computing can bring to this and many other computer vision based science intiatives, using current public available tools such as IBM Qiskit.\n\n## Goals\nThe aim of the project is to develop a Python-based module to perform image matching using quantum computing tools (Qiskit). As an inital approach, the image matching process has been divided into the following tasks:\n\n1. Classical image preparation \n2. Quantum encoding\n3. Quantum edge detection\n4. Quantum image matching\n\nThese tasks will be studied in order to fullfill the **main goal of the project: a minimally viable product (MVP) where 3 classical images (1 reference and 2 proposals) are inputted, encoded, compared and matched**; such as the proposal that best fits the reference is matched with it.  \n\n## Proposed Implementation\n- **Step 1: Image Preparation**\nThis step involves preparing the inital images to adapt our problem to the scope of the hackathon by:\n   - changing from RGB to grayscale format\n   - cropping the image to a square\n   - reducing the resolution to 32 x 32 pixels (this will later mean using 24 qubits in our computation, with the current limit of the qasm simulator being 32 quibts)\n   - centering the city within the image (using centroid)\n   - discarding particularly challenging pictures: those that are cropped, taken from a strange perspective.... \n\nThis is step involves Python classical image processing libraries such as PIL, OpenCV, etc. together with self developed functions.\n\n- **Step 2: Quantum Encoding**\nThe quantum encoding or Quantum Image Representation (QImR) step involves the transformation of the data from a classical to a quantum image representation model [1]. The chosen quantum representation model is key to determine the types of processing tasks and how well they can be performed. After studying different proposals such as NEQR [2], in order to develop our MVP, we have selected to apply Flexible Representation of Quantum Images (FRQI) [3]. This allows us to encode an image of size *m = n x n* (pixels) into *log2(m)* qubits. One of the drawbacks of this representation is the requirement of *m* gates to perform the encoding of such an image.\n\nEven though the main application has been developed using FRQI, we have looked for alterntives to optimize the number of gates required in our circuit. A suggested alternative is the use of a a \"log concave based\" encoding, of which we have attempted a proof of concept with a downscaled example. \n\n- **Step 3: Quantum Edge Detection**\nIn classical image processing, one of the most common steps preceding image matching is edge detection. Several papers have claimed the computational advantage of quantum edge detection compared to the classical counterpart [1], and there have been proposed quantum models that provide a proof of concept such as [1] and [4].  Some other ideas based on the classical approach would be to use quantum support vector machines, inspired by [5].\n\nFor this project, we have implemented the work proposed in [1] that allows to detect horizontal and vertical edges, and find vertices by assesing their overlap in order to construct the image's contour.\n\n- **Step 4: Quantum Image Matching**\nImage matching involves finding similarities between images. These similiarties range from pixel to pixel differences to morphological properties. The qubits used to encode both the test and reference images represent the density matrices for each image. These density matrices can then be compared via a quantum based similarity test. Specifically, this involves a standard SWAP test [6]. \n\n# Framework\n- Language: Python3\n- Quantum API: Qiskit\n- Backend: ibmq_qasm_simulator\n\n# References\n- [1] https://arxiv.org/pdf/1801.01465.pdf\n- [2] https://arxiv.org/pdf/1812.11042.pdf\n- [3] https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf\n- [4] https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm\n- [5] https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf\n- [6] https://arxiv.org/abs/1803.04114\n",html:'<p>A quantum approach to image processing: encoding, edge detection &amp; image matching with a cool application: <em>mapping the Earth at night</em>.</p>\n<h2 id="application-background-and-motivation">Application Background and Motivation</h2>\n<p>Cities at Night (<a href="http://www.citiesatnight.org" target="_blank" rel="noopener">www.citiesatnight.org</a>) is an ongoing project by Alejandro Sanchez de Miguel (U. of Exeter) et al. focused on the creation of a high resolution map of the Earth at night, using color photographs taken by astronauts onboard the ISS.</p>\n<p>NASA has a database with almost 1 million cluttered, unlabeled pictures taken from space over the years. In order to create a high resolution world map, these photographs must be matched with their precise location in the globe\'s surface, a task for which the use of classical machine learning algorithms has been deemed ineffective. The current alternative has been to use citizen science and benefit from the manual matchings carried out by thousands of volunteers, but .... could this approach be improved?</p>\n<p>We think the answer is YES!, and for this hackathon we have decided to explore the benefits quantum computing can bring to this and many other computer vision based science intiatives, using current public available tools such as IBM Qiskit.</p>\n<h2 id="goals">Goals</h2>\n<p>The aim of the project is to develop a Python-based module to perform image matching using quantum computing tools (Qiskit). As an inital approach, the image matching process has been divided into the following tasks:</p>\n<ol>\n<li>Classical image preparation</li>\n<li>Quantum encoding</li>\n<li>Quantum edge detection</li>\n<li>Quantum image matching</li>\n</ol>\n<p>These tasks will be studied in order to fullfill the <strong>main goal of the project: a minimally viable product (MVP) where 3 classical images (1 reference and 2 proposals) are inputted, encoded, compared and matched</strong>; such as the proposal that best fits the reference is matched with it.</p>\n<h2 id="proposed-implementation">Proposed Implementation</h2>\n<ul>\n<li><strong>Step 1: Image Preparation</strong>\nThis step involves preparing the inital images to adapt our problem to the scope of the hackathon by:\n<ul>\n<li>changing from RGB to grayscale format</li>\n<li>cropping the image to a square</li>\n<li>reducing the resolution to 32 x 32 pixels (this will later mean using 24 qubits in our computation, with the current limit of the qasm simulator being 32 quibts)</li>\n<li>centering the city within the image (using centroid)</li>\n<li>discarding particularly challenging pictures: those that are cropped, taken from a strange perspective....</li>\n</ul>\n</li>\n</ul>\n<p>This is step involves Python classical image processing libraries such as PIL, OpenCV, etc. together with self developed functions.</p>\n<ul>\n<li><strong>Step 2: Quantum Encoding</strong>\nThe quantum encoding or Quantum Image Representation (QImR) step involves the transformation of the data from a classical to a quantum image representation model [1]. The chosen quantum representation model is key to determine the types of processing tasks and how well they can be performed. After studying different proposals such as NEQR [2], in order to develop our MVP, we have selected to apply Flexible Representation of Quantum Images (FRQI) [3]. This allows us to encode an image of size <em>m = n x n</em> (pixels) into <em>log2(m)</em> qubits. One of the drawbacks of this representation is the requirement of <em>m</em> gates to perform the encoding of such an image.</li>\n</ul>\n<p>Even though the main application has been developed using FRQI, we have looked for alterntives to optimize the number of gates required in our circuit. A suggested alternative is the use of a a &quot;log concave based&quot; encoding, of which we have attempted a proof of concept with a downscaled example.</p>\n<ul>\n<li><strong>Step 3: Quantum Edge Detection</strong>\nIn classical image processing, one of the most common steps preceding image matching is edge detection. Several papers have claimed the computational advantage of quantum edge detection compared to the classical counterpart [1], and there have been proposed quantum models that provide a proof of concept such as [1] and [4].  Some other ideas based on the classical approach would be to use quantum support vector machines, inspired by [5].</li>\n</ul>\n<p>For this project, we have implemented the work proposed in [1] that allows to detect horizontal and vertical edges, and find vertices by assesing their overlap in order to construct the image\'s contour.</p>\n<ul>\n<li><strong>Step 4: Quantum Image Matching</strong>\nImage matching involves finding similarities between images. These similiarties range from pixel to pixel differences to morphological properties. The qubits used to encode both the test and reference images represent the density matrices for each image. These density matrices can then be compared via a quantum based similarity test. Specifically, this involves a standard SWAP test [6].</li>\n</ul>\n<h1 id="framework">Framework</h1>\n<ul>\n<li>Language: Python3</li>\n<li>Quantum API: Qiskit</li>\n<li>Backend: ibmq_qasm_simulator</li>\n</ul>\n<h1 id="references">References</h1>\n<ul>\n<li>[1] <a href="https://arxiv.org/pdf/1801.01465.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1801.01465.pdf</a></li>\n<li>[2] <a href="https://arxiv.org/pdf/1812.11042.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1812.11042.pdf</a></li>\n<li>[3] <a href="https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf" target="_blank" rel="noopener">https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf</a></li>\n<li>[4] <a href="https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm" target="_blank" rel="noopener">https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm</a></li>\n<li>[5] <a href="https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf" target="_blank" rel="noopener">https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf</a></li>\n<li>[6] <a href="https://arxiv.org/abs/1803.04114" target="_blank" rel="noopener">https://arxiv.org/abs/1803.04114</a></li>\n</ul>\n',attributes:{title:"Quantum Image Processing",author:"Harold Co, Elena Peña Tapia, Nozomi Tanetani, Jean Philippe Arias Zapata, Lucía García Sánchez-Carnerero",description:"A quantum approach to image processing (encoding, edge detection & image matching) with a cool application => mapping the Earth at night.",image:"/images/experiments/quantum-img-processing/img-candidates.png",to:"/experiments/quantum-img-processing",media:["/images/experiments/quantum-img-processing/img-candidates.png"],source:"https://github.com/Shedka/citiesatnight",_meta:{resourcePath:"/home/travis/build/qiskit-community/community.qiskit.org/content/experiments/quantum-img-processing.md"}},vue:{render:"return function render() { var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _vm._m(0) }",staticRenderFns:'return [function () { var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c(\'div\',{staticClass:"content"},[_c(\'p\',[_vm._v("A quantum approach to image processing: encoding, edge detection & image matching with a cool application: "),_c(\'em\',[_vm._v("mapping the Earth at night")]),_vm._v(".")]),_vm._v(" "),_c(\'h2\',{attrs:{"id":"application-background-and-motivation"}},[_vm._v("Application Background and Motivation")]),_vm._v(" "),_c(\'p\',[_vm._v("Cities at Night ("),_c(\'a\',{attrs:{"href":"http://www.citiesatnight.org","target":"_blank","rel":"noopener"}},[_vm._v("www.citiesatnight.org")]),_vm._v(") is an ongoing project by Alejandro Sanchez de Miguel (U. of Exeter) et al. focused on the creation of a high resolution map of the Earth at night, using color photographs taken by astronauts onboard the ISS.")]),_vm._v(" "),_c(\'p\',[_vm._v("NASA has a database with almost 1 million cluttered, unlabeled pictures taken from space over the years. In order to create a high resolution world map, these photographs must be matched with their precise location in the globe\'s surface, a task for which the use of classical machine learning algorithms has been deemed ineffective. The current alternative has been to use citizen science and benefit from the manual matchings carried out by thousands of volunteers, but .... could this approach be improved?")]),_vm._v(" "),_c(\'p\',[_vm._v("We think the answer is YES!, and for this hackathon we have decided to explore the benefits quantum computing can bring to this and many other computer vision based science intiatives, using current public available tools such as IBM Qiskit.")]),_vm._v(" "),_c(\'h2\',{attrs:{"id":"goals"}},[_vm._v("Goals")]),_vm._v(" "),_c(\'p\',[_vm._v("The aim of the project is to develop a Python-based module to perform image matching using quantum computing tools (Qiskit). As an inital approach, the image matching process has been divided into the following tasks:")]),_vm._v(" "),_c(\'ol\',[_c(\'li\',[_vm._v("Classical image preparation")]),_vm._v(" "),_c(\'li\',[_vm._v("Quantum encoding")]),_vm._v(" "),_c(\'li\',[_vm._v("Quantum edge detection")]),_vm._v(" "),_c(\'li\',[_vm._v("Quantum image matching")])]),_vm._v(" "),_c(\'p\',[_vm._v("These tasks will be studied in order to fullfill the "),_c(\'strong\',[_vm._v("main goal of the project: a minimally viable product (MVP) where 3 classical images (1 reference and 2 proposals) are inputted, encoded, compared and matched")]),_vm._v("; such as the proposal that best fits the reference is matched with it.")]),_vm._v(" "),_c(\'h2\',{attrs:{"id":"proposed-implementation"}},[_vm._v("Proposed Implementation")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_c(\'strong\',[_vm._v("Step 1: Image Preparation")]),_vm._v("\\nThis step involves preparing the inital images to adapt our problem to the scope of the hackathon by:\\n"),_c(\'ul\',[_c(\'li\',[_vm._v("changing from RGB to grayscale format")]),_vm._v(" "),_c(\'li\',[_vm._v("cropping the image to a square")]),_vm._v(" "),_c(\'li\',[_vm._v("reducing the resolution to 32 x 32 pixels (this will later mean using 24 qubits in our computation, with the current limit of the qasm simulator being 32 quibts)")]),_vm._v(" "),_c(\'li\',[_vm._v("centering the city within the image (using centroid)")]),_vm._v(" "),_c(\'li\',[_vm._v("discarding particularly challenging pictures: those that are cropped, taken from a strange perspective....")])])])]),_vm._v(" "),_c(\'p\',[_vm._v("This is step involves Python classical image processing libraries such as PIL, OpenCV, etc. together with self developed functions.")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_c(\'strong\',[_vm._v("Step 2: Quantum Encoding")]),_vm._v("\\nThe quantum encoding or Quantum Image Representation (QImR) step involves the transformation of the data from a classical to a quantum image representation model [1]. The chosen quantum representation model is key to determine the types of processing tasks and how well they can be performed. After studying different proposals such as NEQR [2], in order to develop our MVP, we have selected to apply Flexible Representation of Quantum Images (FRQI) [3]. This allows us to encode an image of size "),_c(\'em\',[_vm._v("m = n x n")]),_vm._v(" (pixels) into "),_c(\'em\',[_vm._v("log2(m)")]),_vm._v(" qubits. One of the drawbacks of this representation is the requirement of "),_c(\'em\',[_vm._v("m")]),_vm._v(" gates to perform the encoding of such an image.")])]),_vm._v(" "),_c(\'p\',[_vm._v("Even though the main application has been developed using FRQI, we have looked for alterntives to optimize the number of gates required in our circuit. A suggested alternative is the use of a a \\"log concave based\\" encoding, of which we have attempted a proof of concept with a downscaled example.")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_c(\'strong\',[_vm._v("Step 3: Quantum Edge Detection")]),_vm._v("\\nIn classical image processing, one of the most common steps preceding image matching is edge detection. Several papers have claimed the computational advantage of quantum edge detection compared to the classical counterpart [1], and there have been proposed quantum models that provide a proof of concept such as [1] and [4].  Some other ideas based on the classical approach would be to use quantum support vector machines, inspired by [5].")])]),_vm._v(" "),_c(\'p\',[_vm._v("For this project, we have implemented the work proposed in [1] that allows to detect horizontal and vertical edges, and find vertices by assesing their overlap in order to construct the image\'s contour.")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_c(\'strong\',[_vm._v("Step 4: Quantum Image Matching")]),_vm._v("\\nImage matching involves finding similarities between images. These similiarties range from pixel to pixel differences to morphological properties. The qubits used to encode both the test and reference images represent the density matrices for each image. These density matrices can then be compared via a quantum based similarity test. Specifically, this involves a standard SWAP test [6].")])]),_vm._v(" "),_c(\'h1\',{attrs:{"id":"framework"}},[_vm._v("Framework")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_vm._v("Language: Python3")]),_vm._v(" "),_c(\'li\',[_vm._v("Quantum API: Qiskit")]),_vm._v(" "),_c(\'li\',[_vm._v("Backend: ibmq_qasm_simulator")])]),_vm._v(" "),_c(\'h1\',{attrs:{"id":"references"}},[_vm._v("References")]),_vm._v(" "),_c(\'ul\',[_c(\'li\',[_vm._v("[1] "),_c(\'a\',{attrs:{"href":"https://arxiv.org/pdf/1801.01465.pdf","target":"_blank","rel":"noopener"}},[_vm._v("https://arxiv.org/pdf/1801.01465.pdf")])]),_vm._v(" "),_c(\'li\',[_vm._v("[2] "),_c(\'a\',{attrs:{"href":"https://arxiv.org/pdf/1812.11042.pdf","target":"_blank","rel":"noopener"}},[_vm._v("https://arxiv.org/pdf/1812.11042.pdf")])]),_vm._v(" "),_c(\'li\',[_vm._v("[3] "),_c(\'a\',{attrs:{"href":"https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf","target":"_blank","rel":"noopener"}},[_vm._v("https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf")])]),_vm._v(" "),_c(\'li\',[_vm._v("[4] "),_c(\'a\',{attrs:{"href":"https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm","target":"_blank","rel":"noopener"}},[_vm._v("https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm")])]),_vm._v(" "),_c(\'li\',[_vm._v("[5] "),_c(\'a\',{attrs:{"href":"https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf","target":"_blank","rel":"noopener"}},[_vm._v("https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf")])]),_vm._v(" "),_c(\'li\',[_vm._v("[6] "),_c(\'a\',{attrs:{"href":"https://arxiv.org/abs/1803.04114","target":"_blank","rel":"noopener"}},[_vm._v("https://arxiv.org/abs/1803.04114")])])])]) }]',component:{data:function(){return{templateRender:null}},render:function(e){return this.templateRender?this.templateRender():e("div","Rendering")},created:function(){this.templateRender=function(){var e=this.$createElement;this._self._c;return this._m(0)},this.$options.staticRenderFns=[function(){var e=this,t=e.$createElement,n=e._self._c||t;return n("div",{staticClass:"content"},[n("p",[e._v("A quantum approach to image processing: encoding, edge detection & image matching with a cool application: "),n("em",[e._v("mapping the Earth at night")]),e._v(".")]),e._v(" "),n("h2",{attrs:{id:"application-background-and-motivation"}},[e._v("Application Background and Motivation")]),e._v(" "),n("p",[e._v("Cities at Night ("),n("a",{attrs:{href:"http://www.citiesatnight.org",target:"_blank",rel:"noopener"}},[e._v("www.citiesatnight.org")]),e._v(") is an ongoing project by Alejandro Sanchez de Miguel (U. of Exeter) et al. focused on the creation of a high resolution map of the Earth at night, using color photographs taken by astronauts onboard the ISS.")]),e._v(" "),n("p",[e._v("NASA has a database with almost 1 million cluttered, unlabeled pictures taken from space over the years. In order to create a high resolution world map, these photographs must be matched with their precise location in the globe's surface, a task for which the use of classical machine learning algorithms has been deemed ineffective. The current alternative has been to use citizen science and benefit from the manual matchings carried out by thousands of volunteers, but .... could this approach be improved?")]),e._v(" "),n("p",[e._v("We think the answer is YES!, and for this hackathon we have decided to explore the benefits quantum computing can bring to this and many other computer vision based science intiatives, using current public available tools such as IBM Qiskit.")]),e._v(" "),n("h2",{attrs:{id:"goals"}},[e._v("Goals")]),e._v(" "),n("p",[e._v("The aim of the project is to develop a Python-based module to perform image matching using quantum computing tools (Qiskit). As an inital approach, the image matching process has been divided into the following tasks:")]),e._v(" "),n("ol",[n("li",[e._v("Classical image preparation")]),e._v(" "),n("li",[e._v("Quantum encoding")]),e._v(" "),n("li",[e._v("Quantum edge detection")]),e._v(" "),n("li",[e._v("Quantum image matching")])]),e._v(" "),n("p",[e._v("These tasks will be studied in order to fullfill the "),n("strong",[e._v("main goal of the project: a minimally viable product (MVP) where 3 classical images (1 reference and 2 proposals) are inputted, encoded, compared and matched")]),e._v("; such as the proposal that best fits the reference is matched with it.")]),e._v(" "),n("h2",{attrs:{id:"proposed-implementation"}},[e._v("Proposed Implementation")]),e._v(" "),n("ul",[n("li",[n("strong",[e._v("Step 1: Image Preparation")]),e._v("\nThis step involves preparing the inital images to adapt our problem to the scope of the hackathon by:\n"),n("ul",[n("li",[e._v("changing from RGB to grayscale format")]),e._v(" "),n("li",[e._v("cropping the image to a square")]),e._v(" "),n("li",[e._v("reducing the resolution to 32 x 32 pixels (this will later mean using 24 qubits in our computation, with the current limit of the qasm simulator being 32 quibts)")]),e._v(" "),n("li",[e._v("centering the city within the image (using centroid)")]),e._v(" "),n("li",[e._v("discarding particularly challenging pictures: those that are cropped, taken from a strange perspective....")])])])]),e._v(" "),n("p",[e._v("This is step involves Python classical image processing libraries such as PIL, OpenCV, etc. together with self developed functions.")]),e._v(" "),n("ul",[n("li",[n("strong",[e._v("Step 2: Quantum Encoding")]),e._v("\nThe quantum encoding or Quantum Image Representation (QImR) step involves the transformation of the data from a classical to a quantum image representation model [1]. The chosen quantum representation model is key to determine the types of processing tasks and how well they can be performed. After studying different proposals such as NEQR [2], in order to develop our MVP, we have selected to apply Flexible Representation of Quantum Images (FRQI) [3]. This allows us to encode an image of size "),n("em",[e._v("m = n x n")]),e._v(" (pixels) into "),n("em",[e._v("log2(m)")]),e._v(" qubits. One of the drawbacks of this representation is the requirement of "),n("em",[e._v("m")]),e._v(" gates to perform the encoding of such an image.")])]),e._v(" "),n("p",[e._v('Even though the main application has been developed using FRQI, we have looked for alterntives to optimize the number of gates required in our circuit. A suggested alternative is the use of a a "log concave based" encoding, of which we have attempted a proof of concept with a downscaled example.')]),e._v(" "),n("ul",[n("li",[n("strong",[e._v("Step 3: Quantum Edge Detection")]),e._v("\nIn classical image processing, one of the most common steps preceding image matching is edge detection. Several papers have claimed the computational advantage of quantum edge detection compared to the classical counterpart [1], and there have been proposed quantum models that provide a proof of concept such as [1] and [4].  Some other ideas based on the classical approach would be to use quantum support vector machines, inspired by [5].")])]),e._v(" "),n("p",[e._v("For this project, we have implemented the work proposed in [1] that allows to detect horizontal and vertical edges, and find vertices by assesing their overlap in order to construct the image's contour.")]),e._v(" "),n("ul",[n("li",[n("strong",[e._v("Step 4: Quantum Image Matching")]),e._v("\nImage matching involves finding similarities between images. These similiarties range from pixel to pixel differences to morphological properties. The qubits used to encode both the test and reference images represent the density matrices for each image. These density matrices can then be compared via a quantum based similarity test. Specifically, this involves a standard SWAP test [6].")])]),e._v(" "),n("h1",{attrs:{id:"framework"}},[e._v("Framework")]),e._v(" "),n("ul",[n("li",[e._v("Language: Python3")]),e._v(" "),n("li",[e._v("Quantum API: Qiskit")]),e._v(" "),n("li",[e._v("Backend: ibmq_qasm_simulator")])]),e._v(" "),n("h1",{attrs:{id:"references"}},[e._v("References")]),e._v(" "),n("ul",[n("li",[e._v("[1] "),n("a",{attrs:{href:"https://arxiv.org/pdf/1801.01465.pdf",target:"_blank",rel:"noopener"}},[e._v("https://arxiv.org/pdf/1801.01465.pdf")])]),e._v(" "),n("li",[e._v("[2] "),n("a",{attrs:{href:"https://arxiv.org/pdf/1812.11042.pdf",target:"_blank",rel:"noopener"}},[e._v("https://arxiv.org/pdf/1812.11042.pdf")])]),e._v(" "),n("li",[e._v("[3] "),n("a",{attrs:{href:"https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf",target:"_blank",rel:"noopener"}},[e._v("https://www.jstage.jst.go.jp/article/fss/25/0/25_0_185/_pdf")])]),e._v(" "),n("li",[e._v("[4] "),n("a",{attrs:{href:"https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm",target:"_blank",rel:"noopener"}},[e._v("https://www.researchgate.net/publication/333585825_Quantum_Image_Edge_Detection_Algorithm")])]),e._v(" "),n("li",[e._v("[5] "),n("a",{attrs:{href:"https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf",target:"_blank",rel:"noopener"}},[e._v("https://pdfs.semanticscholar.org/b1d1/e8a9d6173458687bdfdc5a654423444f15b0.pdf")])]),e._v(" "),n("li",[e._v("[6] "),n("a",{attrs:{href:"https://arxiv.org/abs/1803.04114",target:"_blank",rel:"noopener"}},[e._v("https://arxiv.org/abs/1803.04114")])])])])}]}}}}}}]);